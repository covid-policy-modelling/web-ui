#!/usr/bin/env node

const fs = require('fs')
const path = require('path')
const https = require('https')
const URL = require('url')
const {DateTime} = require('luxon')
const mysql = require('serverless-mysql')
const d3 = require('d3')
const _ = require('lodash')
const argv = require('yargs')
  .usage('Usage: $0 --cache-dir [dir] --force')

  .help('h')
  .alias('h', 'help')

  .nargs('c', 1)
  .alias('c', 'cache-dir')
  .describe('c', 'Directory to cache results')

  .boolean('d')
  .alias('d', 'dry-run')
  .describe('f', 'Download and process files, but do not store to database')

  .boolean('f')
  .alias('f', 'force')
  .describe('f', 'Force results even though error check has failed')

  .epilog(
    `
  Download public datasets for covid-19 cases and policy interventions, format these datasets, and write them to MySQL.

  Optionally, pass a path to a dir where downloads should be cached and the results should be written as JSON files.

  To store the results in MySQL, set these environment variables:
  DB_HOST, DB_USERNAME, DB_PASSWORD, DB_DATABASE`
  )
  .version(false).argv

require('ts-node').register({
  project: path.join(__dirname, '../tsconfig.json'),
  compilerOptions: {
    module: 'commonjs'
  }
})
const internationalParser = require('../lib/international-interventions-parser')
const validateFetch = require('../lib/validate-fetch')

const cacheDir = argv.cacheDir
if (cacheDir) {
  console.log(`Using cache directory '${cacheDir}'`)
}
const force = argv.force
if (force) {
  console.warn(
    'Forcing results to be saved to database even if there are validation errors'
  )
}
const dryRun = argv.dryRun

const ecdcCasesURL = `https://opendata.ecdc.europa.eu/covid19/casedistribution/json/`
const covidTrackingURL = `https://api.covidtracking.com/v1/states/daily.json`
const gbDailyCasesURL = `https://api.coronavirus.data.gov.uk/v2/data?areaType=nation&metric=newCasesByPublishDate&metric=newDeathsByPublishDate&format=json` // Mario
const gbInterventionsURL = `https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv`
const usInterventionsURL = `https://raw.githubusercontent.com/COVID19StatePolicy/SocialDistancing/master/data/USstatesCov19distancingpolicy.csv`
const internationalSchoolClosuresURL = `https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c1_school_closing.csv`
const internationalRestrictionsOnGatheringsURL = `https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c4_restrictions_on_gatherings.csv`
const internationalStayAtHomeRequirementsURL = `https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c6_stay_at_home_requirements.csv`

const db = mysql({
  maxRetries: 5,
  config: {
    host: process.env.DB_HOST,
    user: process.env.DB_USERNAME,
    password: process.env.DB_PASSWORD,
    database: process.env.DB_DATABASE,
    ssl: process.env.NODE_ENV === 'production' && {
      ca: fs.readFileSync(
        require.resolve('../lib/BaltimoreCyberTrustRoot.crt.pem'),
        'utf8'
      )
    },
    dateStrings: true
  }
})

async function main() {
  // Fetch the raw data
  const [
    usaCasesJSON,
    ecdcCasesJSON,
    gbCasesJSON,
    gbInterventionsCSV,
    usInterventionsCSV,
    internationalSchoolClosuresCSV,
    internationalRestrictionsOnGatheringsCSV,
    internationalStayAtHomeRequirementsCSV
  ] = await Promise.all([
    fetchCached(covidTrackingURL, cacheDir),
    fetchCached(ecdcCasesURL, cacheDir),
    fetchCached(gbDailyCasesURL, cacheDir),
    fetchCached(gbInterventionsURL, cacheDir),
    fetchCached(usInterventionsURL, cacheDir),
    fetchCached(internationalSchoolClosuresURL, cacheDir),
    fetchCached(internationalRestrictionsOnGatheringsURL, cacheDir),
    fetchCached(internationalStayAtHomeRequirementsURL, cacheDir)
  ])

  // Parse the US case data
  const metricsByState = {}
  const usCaseRecords = JSON.parse(usaCasesJSON)
    .sort((a, b) => a.date - b.date)
    .map(row => {
      const regionID = 'US'
      const subregionID = `US-${row.state}`

      // Date is an integer with digits YYYYMMDD
      const dateSQL = DateTime.fromFormat(
        row.date.toString(),
        'yyyyMMdd'
      ).toISODate()

      // Fill in null values with the last non-null value or zero
      const current =
        metricsByState[row.state] || (metricsByState[row.state] = {})
      current.confirmed = row.positive || current.confirmed || 0
      current.recovered = row.recovered || current.recovered || 0
      current.deaths = row.death || current.deaths || 0

      return [
        regionID,
        subregionID,
        dateSQL,
        current.confirmed,
        current.recovered,
        current.deaths
      ]
    })

  // Parse the non-us case data
  const ecdcCases = JSON.parse(ecdcCasesJSON).records
  const worldRows = _.chain(ecdcCases)
    // Group by country
    .groupBy('geoId')
    // Sort the per day entries so that we can calculate the cumulative values correctly.
    .mapValues(v => _.sortBy(v, [v => toISODate(v.dateRep)]))
    .mapValues(v =>
      _.reduce(
        v,
        (acc, o) => {
          const preCumCases =
            acc.length !== 0 ? acc[acc.length - 1].cumCases : 0
          const preCumDeaths =
            acc.length !== 0 ? acc[acc.length - 1].cumDeaths : 0
          // Create cumulative values in addition to the daily values.
          o.cumCases = preCumCases + parseInt(o.cases)
          o.cumDeaths = preCumDeaths + parseInt(o.deaths)
          acc.push(o)
          return acc
        },
        []
      )
    )
    .values()
    .flatten()
    // Remove any US and UK data since we get that from another source.
    .filter(o => (o.geoId !== 'US') | (o.geoId !== 'UK'))
    .map(o => [o.geoId, null, toISODate(o.dateRep), o.cumCases, 0, o.cumDeaths])
    /*
    .forEach(r => {
      // They use UK as the country code, but we expect GB, so switch them.
      if (r[0] === 'UK') {
        r[0] = 'GB'
      }
    })
    */
    .value()

  // const caseRecords = usCaseRecords.concat(worldRows)
  //const caseRecords = usCaseRecords

  //-----------------------------------------------------------
  // Parse the UK data - ISO value for the UK is GB so use that (despite the fact that
  // Northern Ireland is not in GB but it is in the UK).
  // Schema: https://github.com/covid-modeling/model-runner/blob/master/packages/api/schema/
  const countryMap = Object({
    Wales: 'WLS',
    Scotland: 'SCT',
    England: 'ENG',
    'Northern Ireland': 'NIR'
  })

  const metricsByGBNation = {}
  const gbCaseRecords = JSON.parse(gbCasesJSON)
    .body.sort((a, b) => a.date - b.date)
    .map(row => {
      const regionID = 'GB'
      const subRegion = countryMap[row.areaName]
      const subregionID = `GB-${subRegion}`
      // Date is already a string with the format YYYY-MM-DD
      // but will leave the code below as is
      const dateSQL = DateTime.fromFormat(
        row.date.toString(),
        'yyyy-MM-dd'
      ).toISODate()

      // Fill in null values with the last non-null value or zero
      const current =
        metricsByGBNation[row.areaName] || (metricsByGBNation[row.state] = {})
      current.confirmed =
        row.newCasesByPublishDate || current.newCasesByPublishDate || 0
      // No data about recovered cases
      current.recovered = 0
      current.deaths =
        row.newDeathsByPublishDate || current.newCasesByPublishDate || 0

      return [
        regionID,
        subregionID,
        dateSQL,
        current.confirmed,
        current.recovered,
        current.deaths
      ]
    })

  // const caseRecords = usCaseRecords.concat(worldRows)
  // const caseRecords = gbCaseRecords

  // Parse the GB intervention data, see:
  // https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md
  // https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/interpretation_guide.md
  const gbInterventionRecords = []

  // Start Simon code
  function getNationInterventionData(data, nation) {
    //console.log(`${nation}: ${data}`)
    return data.filter(function(d) {
      return d.RegionName == nation
    })
  }

  function processDateString(dt) {
    return (
      dt.substring(0, 4) + '-' + dt.substring(4, 6) + '-' + dt.substring(6, 8)
    )
  }

  function makeInterventionObject(
    regionId,
    subregionId,
    policyName,
    startDate,
    endDate
  ) {
    return {
      regionId: regionId,
      subregionId: subregionId,
      policy: policyName,
      notes: null,
      source: gbInterventionsURL,
      issueDate: null,
      startDate:
        startDate === null || startDate === undefined ? null : startDate,
      easeDate: null,
      expirationDate: null,
      endDate: endDate === null || endDate === undefined ? null : endDate
    }
  }

  const interventionMapping = Object({
    SchoolClose: {variable: 'C1_School closing', threshold: 2},
    GathRestrict10: {variable: 'C4_Restrictions on gatherings', threshold: 3},
    StayAtHome: {variable: 'C6_Stay at home requirements', threshold: 2}
  })

  const countryMapping = Object({
    'GB-WLS': 'Wales',
    'GB-SCT': 'Scotland',
    'GB-ENG': 'England',
    'GB-NIR': 'Northern Ireland'
  })

  function getInterventions() {
    const subregionIds = Object.keys(countryMapping)
    const interventions = []
    const gbInterventions = d3.csvParse(gbInterventionsCSV)
    for (let s = 0; s < subregionIds.length; s++) {
      const subregionId = subregionIds[s]
      const nation = countryMapping[subregionId]
      const regionId = subregionId.split('-')[0]
      const data = getNationInterventionData(gbInterventions, nation)
      const dt = data.map(function(d) {
        return processDateString(d.Date)
      })
      const policyNames = Object.keys(interventionMapping)
      for (let p = 0; p < policyNames.length; p++) {
        const policyName = policyNames[p]
        const variable = interventionMapping[policyName].variable
        const threshold = interventionMapping[policyName].threshold
        const x = data.map(function(d) {
          return parseFloat(d[variable]) >= threshold
        })
        let start = 0
        let end = 0
        let lastVal = false
        let intervention = {}
        for (let i = 0; i < x.length; i++) {
          if ((x[i] == true) & (lastVal == false)) {
            start = i
          }
          if ((x[i] == false) & (lastVal == true)) {
            end = i
            intervention = makeInterventionObject(
              regionId,
              subregionId,
              policyName,
              dt[start],
              dt[end]
            )
            interventions.push(intervention)
          }
          if ((i == x.length - 1) & (x[i] == true)) {
            intervention = makeInterventionObject(
              regionId,
              subregionId,
              policyName,
              dt[start],
              null
            )
            interventions.push(intervention)
          }
          lastVal = x[i]
        }
      }
    }
    return interventions
  }
  const gbInterventionsRecords = getInterventions()
  // End of Simon's code

  if (cacheDir) {
    fs.writeFileSync(
      path.join(cacheDir, 'uk-case-data.json'),
      JSON.stringify(gbCaseRecords, null, 2),
      'utf8'
    )
    fs.writeFileSync(
      path.join(cacheDir, 'uk-intervention-data.json'),
      JSON.stringify(gbInterventionRecords, null, 2),
      'utf8'
    )
  }
  //}
  //-----------------------------------------------------------

  const caseRecords = usCaseRecords.concat(gbCaseRecords)

  // Parse the US intervention data
  const usInterventionRecords = []
  for (const row of d3.csvParse(usInterventionsCSV)) {
    if (row.StatePolicy && row.StatePostal && row.DateEnacted) {
      const regionId = 'US'
      const subregionId = `US-${row.StatePostal}`
      const policy = row.StatePolicy
      const notes = row.PolicyCodingNotes
      const source = row.PolicySource || null
      const issueDate = row.DateIssued || null
      const startDate = row.DateEnacted
      const easeDate = row.DateEased || null
      const expirationDate = row.DateExpiry || null
      const endDate = row.DateEnded || null
      usInterventionRecords.push({
        regionId,
        subregionId,
        policy,
        notes,
        source,
        issueDate,
        startDate,
        easeDate,
        expirationDate,
        endDate
      })
    }
  }

  // parse the international interventions data
  const internationalSchoolClosures = internationalParser.parseCsv(
    internationalSchoolClosuresCSV,
    'SchoolClose',
    2
  )
  const internationalRestrictionsOnGatherings = internationalParser.parseCsv(
    internationalRestrictionsOnGatheringsCSV,
    'GathRestrict10',
    3
  )
  const internationalStayAtHomeRequirements = internationalParser.parseCsv(
    internationalStayAtHomeRequirementsCSV,
    'StayAtHome',
    2
  )

  const allInterventionRecords = usInterventionRecords
    .concat(internationalSchoolClosures)
    .concat(internationalRestrictionsOnGatherings)
    .concat(internationalStayAtHomeRequirements)
    .concat(gbInterventionsRecords) // Mario
    .filter(row => !!row.startDate)
    .map(row => [
      row.regionId,
      row.subregionId,
      row.policy,
      row.notes,
      row.source,
      row.issueDate,
      row.startDate,
      row.easeDate,
      row.expirationDate,
      row.endDate
    ])

  if (cacheDir) {
    fs.writeFileSync(
      path.join(cacheDir, 'case-data.json'),
      JSON.stringify(caseRecords, null, 2),
      'utf8'
    )

    fs.writeFileSync(
      path.join(cacheDir, 'intervention-data.json'),
      JSON.stringify(allInterventionRecords, null, 2),
      'utf8'
    )
  }

  if (dryRun) {
    console.warn('Skipping storage of results')
    return
  }

  let isError = false
  try {
    console.log('Inserting case data')

    if (!caseRecords.length) {
      throw new Error('No case data found')
    }

    await db.query('START TRANSACTION')

    // Populate the case_data table
    await db.query('CREATE TABLE case_data_import LIKE case_data')
    await db.query(
      `
        INSERT INTO case_data_import
        (region_id, subregion_id, date, confirmed, recovered, deaths)
        VALUES
        ?
      `,
      [caseRecords]
    )

    await validateFetch.validateTableLength(
      db,
      'case_data',
      'case_data_import',
      force
    )

    console.log(`Saved ${caseRecords.length} records to case_data table...`)
    await db.query(
      'RENAME TABLE case_data TO case_data_old, case_data_import TO case_data'
    )

    await db.query('COMMIT')
  } catch (e) {
    console.error('Failed to insert case data')
    console.error(e)
    isError = true
  } finally {
    await db.query('DROP TABLE IF EXISTS case_data_old')
    await db.query('DROP TABLE IF EXISTS case_data_import')
  }

  try {
    console.log('Inserting interventions data')

    if (!allInterventionRecords.length) {
      throw new Error('No interventions found')
    }

    // INTERVENTIONS DATA
    await db.query('START TRANSACTION')
    // Populate the intervention_data table
    await db.query(
      'CREATE TABLE intervention_data_import LIKE intervention_data'
    )
    await db.query(
      `
        INSERT INTO intervention_data_import
        (
          region_id, subregion_id, policy, notes, source,
          issue_date, start_date, ease_date, expiration_date, end_date
        )
        VALUES
        ?
      `,
      [allInterventionRecords]
    )

    await validateFetch.validateTableLength(
      db,
      'intervention_data',
      'intervention_data_import',
      force
    )

    console.log(
      `Saved ${allInterventionRecords.length} records to interventions table...`
    )
    await db.query(
      'RENAME TABLE intervention_data TO intervention_data_old, intervention_data_import TO intervention_data'
    )

    await db.query('COMMIT')
  } catch (e) {
    console.error('Failed to insert interventions data')
    console.error(e)
    isError = true
  } finally {
    await db.query('DROP TABLE IF EXISTS intervention_data_old')
    await db.query('DROP TABLE IF EXISTS intervention_data_import')
  }

  if (isError) {
    console.error('Failed to complete all tasks')
    process.exit(1)
  }
}

async function fetchCached(url, cacheDir) {
  let cacheFilename = path.basename(url)

  // UK URL not friendly for the file to be saved
  if (url.includes('data.gov.uk')) {
    cacheFilename = 'gb-data.json'
  }

  const cachePath = cacheDir && path.join(cacheDir, cacheFilename)

  if (cachePath && fs.existsSync(cachePath)) {
    console.log(`Using existing download ${cachePath}...`)
    return fs.readFileSync(cachePath, 'utf8')
  } else {
    console.log(`Downloading from ${url}...`)
    let result = ''
    await new Promise((resolve, reject) => {
      fetch(url)
      function fetch(url) {
        https.get(url, res => {
          // Follow path redirects
          if (res.statusCode === 301 || res.statusCode === 302) {
            const oldURL = URL.parse(url)
            const locationURL = URL.parse(res.headers.location)
            oldURL.path = locationURL.path
            oldURL.pathname = locationURL.pathname
            oldURL.href = null
            const redirectURL = URL.format(oldURL)
            console.log(`Redirected\n  from ${url}\n  to ${redirectURL}...`)
            fetch(redirectURL)
          } else {
            res.on('data', chunk => (result += chunk))
            res.on('end', resolve)
            res.on('error', reject)
          }
        })
      }
    })

    if (cacheDir) {
      if (!fs.existsSync(cacheDir)) {
        console.log(`Cache directory ${cacheDir} does not exist. Creating ...`)
        fs.mkdirSync(cacheDir)
      }
    }

    if (cachePath) {
      console.log(`Saving download to ${cachePath}...`)
      fs.writeFileSync(cachePath, result, 'utf8')
    }
    return result
  }
}

function toISODate(dateRep) {
  return DateTime.fromFormat(dateRep, 'dd/MM/yyyy').toISODate()
}

main()
  .then(() => {
    process.exit(0)
  })
  .catch(error => {
    console.error(error)
    process.exit(1)
  })
